{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importação de pacotes and utilitarios\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "import plotly.express as px \n",
    "import plotly.io as pio\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objects as go\n",
    "pio.renderers.default='browser'\n",
    "\n",
    "def convertToNumber(banco, coluna):\n",
    "    banco[coluna] = pd.to_numeric(banco[coluna], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação de banco de dados\n",
    "dados_pisa = pd.read_csv('./bancos_dados/notas_pisa.csv', delimiter=',')\n",
    "dados_pisa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Em um primeiro momento só iremos utilizar as notas de 2022, \n",
    " por este motivo será gerado outro banco de dados sem as notas de 2018\n",
    " E faremos o tratamento dos dados\n",
    "\"\"\"\n",
    "\n",
    "#remove as colunas que não usaremos\n",
    "if 'mathematics_2018' in dados_pisa.columns:\n",
    "    dados_pisa.drop(columns=['mathematics_2018', 'reading_2018', 'science_2018'], inplace=True)\n",
    "\n",
    "#realizarmos padronização dos dados, pois as notas estão em formato texto, iremos transformar para numeros\n",
    "convertToNumber(dados_pisa, 'mathematics_2022')\n",
    "convertToNumber(dados_pisa, 'reading_2022')\n",
    "convertToNumber(dados_pisa, 'science_2022')\n",
    "\n",
    "#remove as linhas NAN\n",
    "dados_pisa.dropna(inplace=True)\n",
    "dados_pisa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iremos iniciar com a analise PCA\n",
    "\n",
    "\"\"\"para gerar o mapa de calor a matriz deve possuir apenas dados categoricos, por isso iremos remover\n",
    "as varveis COUNTRY E GROUP, porem agora iremos gerar outro dataFrame para manter o original e\n",
    "depois fazer um merge \"\"\"\n",
    "\n",
    "pisa_pca = dados_pisa.drop(columns=['country', 'group'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração de mapa de calor para verificar se existe relação forte entre as variaveis\n",
    "# Esta mapa é gerado apartir de uma matriz de correção, esta matriz é gerada pelo comando pisa_pca.corr()\n",
    "# INTERPRETAÇÃO - no mapa de calor, quanto mais perto de 1, maior é a relação entre as variaveis\n",
    "sns.heatmap(pisa_pca.corr(), annot=True, \n",
    "            cmap = plt.cm.Purples,\n",
    "            annot_kws={'size':7})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
